{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2303275f",
   "metadata": {},
   "source": [
    "# HW requirements \n",
    "Solve the following problem using [Python SciPy.optimize][]. Please attach your code and\n",
    "results. Specify your initial guesses of the solution. If you change\n",
    "your initial guess, do you find different solutions? (**100 points**)\n",
    "\n",
    "$$\\begin{aligned} &\\text{minimize:} && (x_1-x_2)^2 + (x_2+x_3-2)^2 + (x_4-1)^2+(x_5-1)^2 \\\\ &\\text{subject to:} && x_1 + 3x_2 = 0 \\\\ &&& x_3 + x_4 - 2x_5 = 0 \\\\ &&& x_2 - x_5 = 0 \\\\ &&& -10 \\leq x_i \\leq 10, ~i=1,\\ldots,5 \\end{aligned}$$\n",
    "**Note**:\n",
    "\n",
    "1.  Please learn how to use **break points** to debug. **I will not\n",
    "    address your programming questions if you have not learned how to\n",
    "    debug your code.**\n",
    "\n",
    "2.  I recommend [PyCharm][] as the IDE. If you are new to Python, you can also start with [Google Colab][] without installing anything.\n",
    "    \n",
    "3.  If you are on Windows, the [Anaconda][] version of Python 3 is highly recommended.\n",
    "\n",
    "\n",
    "**Here are the steps to push a homework submission**:\n",
    "\n",
    "1.  Clone the [course repo][]: First click on **Code** to get the\n",
    " Git address (e.g., the HTTPS address). Then use your IDE to clone (download) the repo using this address. \n",
    " [PyCharm tutorial on using Git][].\n",
    "\n",
    "2.  You will find the homework in the **Homework** folder.\n",
    "\n",
    "3.  For analytical problems (e.g., proofs and calculations), please use [Markdown][] to type up your answers. \n",
    "[Markdown Math][]. For Latex users, you can convert tex to markdown using [Pandoc][]. \n",
    "\n",
    "4. For coding problems, please submit a [Jupyter Notebook][] file with your code and final results. \n",
    "You can also add a URL to your Jupyter or Colab Notebook in README.md if you use online notebooks.\n",
    "\n",
    "5. For each homework, please submit a single notebook file (or link) that combines the markdown solutions, \n",
    "the codes, and the computation results, and name the file according to the homework.  \n",
    "\n",
    "6. **IMPORTANT** Please push (upload) the notebook file every time you work on the \n",
    "homework and add comments when you push, e.g., \"finished problem 1, still debugging problem 2\". This way I \n",
    "know you worked on your own.\n",
    " \n",
    "\n",
    "[Python SciPy.optimize]: https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html#\n",
    "[PyCharm]: https://www.jetbrains.com/pycharm/promo/?utm_source=bing&utm_medium=cpc&utm_campaign=AMER_en_US-PST%2BMST_PyCharm_Branded&utm_term=pycharm&utm_content=pycharm\n",
    "[Google Colab]: https://colab.research.google.com\n",
    "[Anaconda]: https://anaconda.org/anaconda/python\n",
    "[course repo]: https://github.com/DesignInformaticsLab/DesignOptimization2021Fall\n",
    "[PyCharm tutorial]: https://www.jetbrains.com/help/pycharm/set-up-a-git-repository.html#clone-repo\n",
    "[Pandoc]: https://pandoc.org/try/\n",
    "[Jupyter Notebook]: https://jupyter.org/try\n",
    "[Markdown]: https://guides.github.com/features/mastering-markdown/\n",
    "[Markdown Math]: http://luvxuan.top/posts/Markdown-math/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06e03c8",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "The initial guess is set to be [1,2,3,4,-10] first, and then I change the 5th elements of initial guess several times. With different initial guesses in these cases,the minimum of the objective function is the same.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e074bc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 4.093023255813955\n",
      "     jac: array([-2.04651159, -0.18604642, -2.23255807, -2.23255813, -1.48837209])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 26\n",
      "     nit: 4\n",
      "    njev: 4\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76744186,  0.25581395,  0.62790698, -0.11627907,  0.25581395])\n",
      "     fun: 4.093023255813955\n",
      "     jac: array([-2.04651159, -0.18604642, -2.23255807, -2.23255813, -1.48837209])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 26\n",
      "     nit: 4\n",
      "    njev: 4\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76744186,  0.25581395,  0.62790698, -0.11627907,  0.25581395])\n",
      "     fun: 4.0930232558139545\n",
      "     jac: array([-2.04651165, -0.18604648, -2.23255813, -2.23255813, -1.48837203])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 26\n",
      "     nit: 4\n",
      "    njev: 4\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76744186,  0.25581395,  0.62790698, -0.11627907,  0.25581395])\n",
      "     fun: 4.093023255813951\n",
      "     jac: array([-2.04651159, -0.18604648, -2.23255813, -2.23255807, -1.48837209])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 26\n",
      "     nit: 4\n",
      "    njev: 4\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76744186,  0.25581395,  0.62790698, -0.11627907,  0.25581395])\n",
      "     fun: 4.093023317486933\n",
      "     jac: array([-2.04611528, -0.1867249 , -2.23284012, -2.23257345, -1.48847115])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 31\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76729322,  0.25576441,  0.62781553, -0.11628671,  0.25576441])\n",
      "     fun: 4.093023255816244\n",
      "     jac: array([-2.04651403, -0.18604237, -2.23255634, -2.23255807, -1.48837143])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 37\n",
      "     nit: 6\n",
      "    njev: 6\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76744276,  0.25581425,  0.62790756, -0.11627905,  0.25581425])\n",
      "     fun: 4.0930232560650595\n",
      "     jac: array([-2.04653656, -0.18600303, -2.23253959, -2.23255789, -1.48836583])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 37\n",
      "     nit: 6\n",
      "    njev: 6\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76745122,  0.25581707,  0.62791311, -0.11627896,  0.25581707])\n",
      "     fun: 4.093023261963524\n",
      "     jac: array([-2.04663402, -0.18583095, -2.23246491, -2.23255956, -1.48834145])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 37\n",
      "     nit: 6\n",
      "    njev: 6\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76748775,  0.25582925,  0.62793828, -0.11627978,  0.25582925])\n",
      "     fun: 4.093023321636826\n",
      "     jac: array([-2.0469076 , -0.18533987, -2.23224747, -2.2325719 , -1.48827308])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 37\n",
      "     nit: 6\n",
      "    njev: 6\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76759034,  0.25586345,  0.62801284, -0.11628594,  0.25586345])\n",
      "     fun: 4.093023287827268\n",
      "     jac: array([-2.04627013, -0.18653613, -2.23280632, -2.23249102, -1.48843241])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 43\n",
      "     nit: 7\n",
      "    njev: 7\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76735132,  0.25578377,  0.62781306, -0.11624551,  0.25578377])\n",
      "     fun: 4.093023288395995\n",
      "     jac: array([-2.04628617, -0.18653256, -2.23281878, -2.23246664, -1.48842847])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 43\n",
      "     nit: 7\n",
      "    njev: 7\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.7673573 ,  0.25578577,  0.62780485, -0.11623331,  0.25578577])\n",
      "     fun: 4.093023313108912\n",
      "     jac: array([-2.04624265, -0.18667316, -2.23291588, -2.23240209, -1.48843932])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 43\n",
      "     nit: 7\n",
      "    njev: 7\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76734101,  0.25578034,  0.62776172, -0.11620105,  0.25578034])\n",
      "     fun: 4.093023379590909\n",
      "     jac: array([-2.04616189, -0.18693399, -2.23309588, -2.23228264, -1.48845947])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 43\n",
      "     nit: 7\n",
      "    njev: 7\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76731071,  0.25577024,  0.62768178, -0.11614131,  0.25577024])\n",
      "     fun: 4.093023472103976\n",
      "     jac: array([-2.04609454, -0.18718195, -2.23327643, -2.23215276, -1.4884764 ])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 43\n",
      "     nit: 7\n",
      "    njev: 7\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76728543,  0.25576181,  0.62759999, -0.11607637,  0.25576181])\n",
      "     fun: 4.093023565107985\n",
      "     jac: array([-2.04603654, -0.187383  , -2.2334196 , -2.23205292, -1.48849088])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 43\n",
      "     nit: 7\n",
      "    njev: 7\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76726372,  0.25575457,  0.62753561, -0.11602647,  0.25575457])\n",
      "     fun: 4.09302369133629\n",
      "     jac: array([-2.04594326, -0.18763667, -2.23357999, -2.23196256, -1.48851418])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 43\n",
      "     nit: 7\n",
      "    njev: 7\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76722873,  0.25574291,  0.6274671 , -0.11598127,  0.25574291])\n",
      "     fun: 4.09302325588931\n",
      "     jac: array([-2.04579037, -0.18800253, -2.2337929 , -2.23186433, -1.48855239])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 44\n",
      "     nit: 7\n",
      "    njev: 7\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76743912,  0.25581304,  0.62791188, -0.1162858 ,  0.25581304])\n",
      "     fun: 4.093023255911077\n",
      "     jac: array([-2.04559267, -0.18843663, -2.23402935, -2.23177612, -1.4886018 ])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 44\n",
      "     nit: 7\n",
      "    njev: 7\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76743889,  0.25581296,  0.62791265, -0.11628672,  0.25581296])\n",
      "     fun: 4.093023255928415\n",
      "     jac: array([-2.04650348, -0.18604416, -2.23254764, -2.23257476, -1.48837411])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 49\n",
      "     nit: 8\n",
      "    njev: 8\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.7674388 ,  0.25581293,  0.62791325, -0.11628739,  0.25581293])\n",
      "     fun: 4.09302325593708\n",
      "     jac: array([-2.04650354, -0.18604326, -2.23254681, -2.23257542, -1.48837405])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 49\n",
      "     nit: 8\n",
      "    njev: 8\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76743885,  0.25581295,  0.6279136 , -0.1162877 ,  0.25581295])\n",
      "     fun: 4.093023255933288\n",
      "     jac: array([-2.04650414, -0.18604261, -2.23254675, -2.23257512, -1.48837394])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 49\n",
      "     nit: 8\n",
      "    njev: 8\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76743906,  0.25581302,  0.6279136 , -0.11628756,  0.25581302])\n",
      "     fun: 4.09302345872417\n",
      "     jac: array([-2.04599202, -0.18723464, -2.23322678, -2.23227918, -1.48850197])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 42\n",
      "     nit: 7\n",
      "    njev: 7\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-0.76724703,  0.25574901,  0.62763762, -0.1161396 ,  0.25574901])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "##function and constraint \n",
    "objective_function = lambda x: (x[0]-x[1])**2 +(x[1]+x[2]-2)**2+(x[3]-1)**2+(x[4]-1)**2\n",
    "constraint1 = lambda x :x[0]+3*x[1]\n",
    "constraint2 = lambda x :x[2]+x[3]-2*x[4]\n",
    "constraint3 = lambda x :x[1]-x[4]\n",
    "constraints =[{'type':'eq','fun':constraint1},{'type':'eq','fun':constraint2},\n",
    "             {'type':'eq','fun':constraint3}]\n",
    "\n",
    "x0=[1,2,3,4,-10] ## initial input, later we set the x0[4] to be different values\n",
    "b=(-10,10)  ## variable bounds\n",
    "bounds=[b,b,b,b,b]\n",
    "##bounds=((-10,10),(-10,10),(-10,10),(-10,10),(-10,10))\n",
    "\n",
    "##see the result for one spepcific initial guess\n",
    "result= minimize(objective_function,x0,method='SLSQP', bounds = bounds , constraints=constraints)\n",
    "print(result)\n",
    " ## get minimum function value with different initial values \n",
    "while x0[4]<11: \n",
    "    result= minimize(objective_function,x0,method='SLSQP', bounds = bounds , constraints=constraints)\n",
    "    ##print('When the 5th elements of initial guess is',x0[4],'the minimum objective function value we find is',result.fun)\n",
    "    print(result)\n",
    "    x0[4]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b215fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
